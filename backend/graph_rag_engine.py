"""
Graph-Guided RAG ì—”ì§„
Neo4j ê·¸ë˜í”„ë¥¼ í™œìš©í•œ ë§¥ë½ ê¸°ë°˜ ê·œì • ê²€ìƒ‰
"""
from typing import List, Dict, Any, Optional, Tuple
from neo4j import GraphDatabase
import openai
from dataclasses import dataclass
import json


@dataclass
class ReasoningStep:
    """ì¶”ë¡  ë‹¨ê³„ ê¸°ë¡ìš© ë°ì´í„° í´ë˜ìŠ¤"""
    step_name: str
    step_number: int
    description: str
    query: Optional[str] = None
    results: Optional[List[Dict]] = None
    reasoning: Optional[str] = None


class GraphGuidedRAG:
    """íŒ”ë€í‹°ì–´ì‹ Graph-Guided RAG ì—”ì§„"""

    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str,
                 openai_api_key: str, llm_model: str = "gpt-4"):
        """
        Args:
            neo4j_uri: Neo4j ë°ì´í„°ë² ì´ìŠ¤ URI
            neo4j_user: Neo4j ì‚¬ìš©ìëª…
            neo4j_password: Neo4j ë¹„ë°€ë²ˆí˜¸
            openai_api_key: OpenAI API í‚¤
            llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸
        """
        self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        openai.api_key = openai_api_key
        self.llm_model = llm_model
        self.reasoning_history: List[ReasoningStep] = []

    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        self.driver.close()

    def reset_reasoning_history(self):
        """ì¶”ë¡  ê¸°ë¡ ì´ˆê¸°í™”"""
        self.reasoning_history = []

    def add_reasoning_step(self, step: ReasoningStep):
        """ì¶”ë¡  ë‹¨ê³„ ê¸°ë¡"""
        self.reasoning_history.append(step)

    def analyze_situation(self, situation_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ìƒí™© ë¶„ì„ ë° ê´€ë ¨ ê·œì •/ì‚¬ë¡€ ê²€ìƒ‰

        Args:
            situation_data: ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°

        Returns:
            ë¶„ì„ ê²°ê³¼ ë° ì¶”ì²œ ì¡°ì¹˜
        """
        self.reset_reasoning_history()

        # Step 1: Perception - ìƒí™© íŒŒì•…
        perception = self._step1_perception(situation_data)

        # Step 2: Graph Context - ê·¸ë˜í”„ì—ì„œ ìƒí™© ë§¥ë½ ì¶”ì¶œ
        graph_context = self._step2_graph_context(perception)

        # Step 3: Rule Retrieval - ì ìš© ê·œì • ê²€ìƒ‰
        relevant_rules = self._step3_rule_retrieval(graph_context)

        # Step 4: Case Retrieval - ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
        relevant_cases = self._step4_case_retrieval(graph_context, relevant_rules)

        # Step 5: LLM Analysis - ì¢…í•© ë¶„ì„
        analysis = self._step5_llm_analysis(
            situation_data, relevant_rules, relevant_cases
        )

        # Step 6: Action Recommendation - ì¡°ì¹˜ ê¶Œê³ 
        recommendations = self._step6_action_recommendation(
            situation_data, relevant_rules, relevant_cases, analysis
        )

        return {
            "situation": situation_data,
            "perception": perception,
            "graph_context": graph_context,
            "relevant_rules": relevant_rules,
            "relevant_cases": relevant_cases,
            "analysis": analysis,
            "recommendations": recommendations,
            "reasoning_history": [
                {
                    "step_name": step.step_name,
                    "step_number": step.step_number,
                    "description": step.description,
                    "reasoning": step.reasoning,
                    "results_count": len(step.results) if step.results else 0
                }
                for step in self.reasoning_history
            ]
        }

    def _step1_perception(self, situation_data: Dict[str, Any]) -> Dict[str, Any]:
        """Step 1: ìƒí™© ì¸ì‹ ë° í•µì‹¬ ìš”ì†Œ ì¶”ì¶œ"""
        situation = situation_data.get('situation', {})
        own_ship = situation.get('own_ship', {})
        targets = situation.get('target_vessels', [])

        perception = {
            "visibility": situation.get('visibility'),
            "own_ship_type": own_ship.get('type'),
            "own_ship_speed": own_ship.get('speed'),
            "target_count": len(targets),
            "targets": []
        }

        # ê° íƒ€ê²Ÿ ì„ ë°• ë¶„ì„
        for target in targets:
            target_info = {
                "type": target.get('type'),
                "bearing": target.get('bearing'),
                "distance": target.get('distance'),
                "cpa": target.get('cpa'),
                "tcpa": target.get('tcpa'),
                "relative_position": target.get('relative_position'),
                "status": target.get('vessel_status')
            }
            perception["targets"].append(target_info)

        self.add_reasoning_step(ReasoningStep(
            step_name="Perception",
            step_number=1,
            description="YOLO ë° ì„¼ì„œ ë°ì´í„°ë¡œë¶€í„° ìƒí™© ì¸ì‹",
            results=[perception],
            reasoning=f"ì‹œê³„: {perception['visibility']}, ë³¸ì„ : {perception['own_ship_type']}, íƒ€ì„ : {perception['target_count']}ì²™"
        ))

        return perception

    def _step2_graph_context(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """Step 2: ê·¸ë˜í”„ì—ì„œ ìƒí™© ë§¥ë½ íŒŒì•…"""
        # ìƒí™© íƒ€ì… íŒë‹¨
        situation_types = self._determine_situation_types(perception)

        # Neo4jì—ì„œ ê´€ë ¨ SituationType ë…¸ë“œ ê²€ìƒ‰
        with self.driver.session() as session:
            query = """
            MATCH (st:SituationType)
            WHERE st.name IN $situation_types
            OPTIONAL MATCH (st)<-[:APPLIES_TO]-(r:Rule)
            OPTIONAL MATCH (st)<-[:OCCURRED_IN]-(c:Case)
            RETURN st.name as situation_type,
                   count(DISTINCT r) as rule_count,
                   count(DISTINCT c) as case_count
            """
            results = session.run(query, situation_types=situation_types)
            graph_data = [dict(record) for record in results]

        context = {
            "identified_situations": situation_types,
            "graph_nodes": graph_data
        }

        self.add_reasoning_step(ReasoningStep(
            step_name="Graph Context",
            step_number=2,
            description="Neo4j ê·¸ë˜í”„ì—ì„œ ìƒí™© ë§¥ë½ ì¶”ì¶œ",
            query=query,
            results=graph_data,
            reasoning=f"ì‹ë³„ëœ ìƒí™©: {', '.join(situation_types)}"
        ))

        return context

    def _determine_situation_types(self, perception: Dict[str, Any]) -> List[str]:
        """ì¸ì‹ ë°ì´í„°ë¡œë¶€í„° ìƒí™© íƒ€ì… ì¶”ë¡ """
        situation_types = []

        # ì‹œì • ì¡°ê±´
        visibility = perception.get("visibility", "")
        if any(keyword in visibility for keyword in ["ì•ˆê°œ", "ë†ë¬´", "ëˆˆ", "ë¹„", "50ë¯¸í„°", "100ë¯¸í„°"]):
            situation_types.append("ì‹œê³„ ì œí•œ ìƒí™©")

        # íƒ€ì„  ìœ„ì¹˜ ê¸°ë°˜ ìƒí™© íŒë‹¨
        for target in perception.get("targets", []):
            rel_pos = target.get("relative_position", "")
            bearing = target.get("bearing")

            if rel_pos == "ìš°í˜„" or "ìš°í˜„" in str(rel_pos):
                situation_types.append("íš¡ë‹¨ ìƒí™©")
            elif bearing and "ì •ë©´" in str(bearing):
                situation_types.append("ë§ˆì£¼ì¹˜ëŠ” ìƒí™©")

            # ì„ ë°• íƒ€ì… ê¸°ë°˜
            target_type = target.get("type", "")
            if "ì–´ì„ " in target_type:
                situation_types.append("ê°ì¢… ì„ ë°• ê°„ ì±…ì„")

        # ìœ„ì¹˜ ê¸°ë°˜
        own_position = perception.get("own_ship_position", "")
        if "í˜‘ìˆ˜ë¡œ" in own_position or "TSS" in own_position:
            situation_types.append("ì¢ì€ ìˆ˜ë¡œ")

        # ì¤‘ë³µ ì œê±°
        return list(set(situation_types)) if situation_types else ["ì¼ë°˜ í•­í–‰"]

    def _step3_rule_retrieval(self, graph_context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Step 3: ì ìš© ê°€ëŠ¥í•œ COLREGs ê·œì • ê²€ìƒ‰"""
        situation_types = graph_context.get("identified_situations", [])

        with self.driver.session() as session:
            query = """
            MATCH (r:Rule)-[:APPLIES_TO]->(st:SituationType)
            WHERE st.name IN $situation_types
            RETURN DISTINCT r.id as rule_id,
                   r.title as title,
                   r.summary as summary,
                   r.full_text as full_text,
                   r.legal_weight as legal_weight,
                   collect(DISTINCT st.name) as situations
            ORDER BY r.legal_weight DESC
            LIMIT 5
            """
            results = session.run(query, situation_types=situation_types)
            rules = [dict(record) for record in results]

        self.add_reasoning_step(ReasoningStep(
            step_name="Rule Retrieval",
            step_number=3,
            description="ê·¸ë˜í”„ ê¸°ë°˜ ê´€ë ¨ ê·œì • ê²€ìƒ‰",
            query=query,
            results=rules,
            reasoning=f"{len(rules)}ê°œì˜ ê´€ë ¨ ê·œì • ê²€ìƒ‰ ì™„ë£Œ"
        ))

        return rules

    def _step4_case_retrieval(self, graph_context: Dict[str, Any],
                               relevant_rules: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Step 4: ìœ ì‚¬ ì‚¬ê³  ì‚¬ë¡€ ê²€ìƒ‰"""
        rule_ids = [rule['rule_id'] for rule in relevant_rules]

        with self.driver.session() as session:
            query = """
            MATCH (c:Case)-[:VIOLATED]->(r:Rule)
            WHERE r.id IN $rule_ids
            OPTIONAL MATCH (c)-[:TEACHES]->(l:Lesson)
            RETURN DISTINCT c.case_id as case_id,
                   c.title as title,
                   c.situation_type as situation_type,
                   c.analysis as analysis,
                   c.judgment as judgment,
                   collect(DISTINCT l.text) as lessons
            ORDER BY c.legal_weight DESC
            LIMIT 3
            """
            results = session.run(query, rule_ids=rule_ids)
            cases = [dict(record) for record in results]

        self.add_reasoning_step(ReasoningStep(
            step_name="Case Retrieval",
            step_number=4,
            description="ìœ ì‚¬ ì‚¬ê³  íŒë¡€ ê²€ìƒ‰",
            query=query,
            results=cases,
            reasoning=f"{len(cases)}ê°œì˜ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì™„ë£Œ"
        ))

        return cases

    def _step5_llm_analysis(self, situation_data: Dict[str, Any],
                            rules: List[Dict[str, Any]],
                            cases: List[Dict[str, Any]]) -> str:
        """Step 5: LLMì„ í™œìš©í•œ ì¢…í•© ë¶„ì„"""
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_analysis_prompt(situation_data, rules, cases)

        # LLM í˜¸ì¶œ
        try:
            response = openai.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ êµ­ì œí•´ìƒì¶©ëŒë°©ì§€ê·œì¹™(COLREGs) ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            analysis = response.choices[0].message.content
        except Exception as e:
            analysis = f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}\n\nê¸°ë³¸ ë¶„ì„: ê´€ë ¨ ê·œì • {len(rules)}ê°œ, ìœ ì‚¬ ì‚¬ë¡€ {len(cases)}ê°œ ê²€í†  í•„ìš”."

        self.add_reasoning_step(ReasoningStep(
            step_name="LLM Analysis",
            step_number=5,
            description="LLM ê¸°ë°˜ ì¢…í•© ë¶„ì„",
            reasoning=analysis
        ))

        return analysis

    def _build_analysis_prompt(self, situation: Dict[str, Any],
                                rules: List[Dict[str, Any]],
                                cases: List[Dict[str, Any]]) -> str:
        """LLM ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        prompt = f"""
í˜„ì¬ í•´ìƒ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ìš© ê°€ëŠ¥í•œ COLREGs ê·œì •ê³¼ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨ì„ ì œì‹œí•˜ì„¸ìš”.

## í˜„ì¬ ìƒí™©
{json.dumps(situation.get('situation', {}), ensure_ascii=False, indent=2)}

## ì ìš© ê°€ëŠ¥í•œ COLREGs ê·œì •
"""
        for i, rule in enumerate(rules, 1):
            prompt += f"\n### {i}. {rule['title']}\n"
            prompt += f"ìš”ì•½: {rule['summary']}\n"

        prompt += "\n## ìœ ì‚¬ ì‚¬ê³  ì‚¬ë¡€\n"
        for i, case in enumerate(cases, 1):
            prompt += f"\n### {i}. {case['title']}\n"
            prompt += f"ìƒí™©: {case['situation_type']}\n"
            prompt += f"íŒë‹¨: {case['judgment'][:200]}...\n"

        prompt += """

## ë¶„ì„ ìš”ì²­
1. í˜„ì¬ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ê·œì •ì€ ë¬´ì—‡ì¸ê°€?
2. ìœ ì‚¬ ì‚¬ë¡€ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” êµí›ˆì€?
3. ë³¸ì„ ì˜ ë²•ì  ì§€ìœ„ëŠ”? (í”¼í•­ì„ /ìœ ì§€ì„ /ê¸°íƒ€)
4. ì˜ˆìƒë˜ëŠ” ìœ„í—˜ ìš”ì†ŒëŠ”?

ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        return prompt

    def _step6_action_recommendation(self, situation: Dict[str, Any],
                                      rules: List[Dict[str, Any]],
                                      cases: List[Dict[str, Any]],
                                      analysis: str) -> Dict[str, Any]:
        """Step 6: êµ¬ì²´ì ì¸ ì¡°ì¹˜ ê¶Œê³ """
        # ì‹œë‚˜ë¦¬ì˜¤ì— ì •ë‹µì´ ìˆë‹¤ë©´ ì‚¬ìš©
        if 'correct_actions' in situation:
            recommended_actions = situation['correct_actions']
        else:
            # LLMìœ¼ë¡œ ì¡°ì¹˜ ìƒì„±
            recommended_actions = self._generate_actions_with_llm(situation, rules, analysis)

        recommendations = {
            "priority_actions": recommended_actions[:3] if isinstance(recommended_actions, list) else [],
            "legal_basis": [rule['rule_id'] for rule in rules[:2]],
            "warnings": situation.get('critical_warnings', []),
            "key_lessons": cases[0].get('lessons', []) if cases else []
        }

        self.add_reasoning_step(ReasoningStep(
            step_name="Action Recommendation",
            step_number=6,
            description="êµ¬ì²´ì ì¸ ì¡°ì¹˜ ê¶Œê³  ìƒì„±",
            results=[recommendations],
            reasoning=f"{len(recommended_actions)}ê°œì˜ ìš°ì„  ì¡°ì¹˜ ê¶Œê³ "
        ))

        return recommendations

    def _generate_actions_with_llm(self, situation: Dict[str, Any],
                                    rules: List[Dict[str, Any]],
                                    analysis: str) -> List[Dict[str, Any]]:
        """LLMìœ¼ë¡œ ì¡°ì¹˜ ìƒì„± (ì‹œë‚˜ë¦¬ì˜¤ì— ì •ë‹µì´ ì—†ì„ ê²½ìš°)"""
        # ê°„ë‹¨í•œ ê¸°ë³¸ ì¡°ì¹˜ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” LLM í˜¸ì¶œ)
        return [
            {
                "action": "ê²½ê³„ ê°•í™”",
                "priority": 1,
                "colregs": rules[0]['rule_id'] if rules else "rule_05"
            },
            {
                "action": "ì†ë ¥ ì¡°ì ˆ",
                "priority": 2,
                "colregs": "rule_06"
            }
        ]


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import os

    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
    NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
    NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
    NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

    # RAG ì—”ì§„ ì´ˆê¸°í™”
    rag = GraphGuidedRAG(
        neo4j_uri=NEO4J_URI,
        neo4j_user=NEO4J_USER,
        neo4j_password=NEO4J_PASSWORD,
        openai_api_key=OPENAI_API_KEY
    )

    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ
    with open("/home/user/HASS/data/raw/demo_scenarios.json", 'r', encoding='utf-8') as f:
        scenarios = json.load(f)

    # ì²« ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
    result = rag.analyze_situation(scenarios[0])

    print("ğŸ¯ ë¶„ì„ ê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    rag.close()
